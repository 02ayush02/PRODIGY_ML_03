{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe877aa-91b5-4c2f-aed1-685ee87b50f2",
   "metadata": {},
   "source": [
    "# Task 3: Implement a Support Vector Machine (SVM) to classify images of cats and dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b43cec-81b0-4c21-b3f4-7c5fbabb2527",
   "metadata": {},
   "source": [
    "## Cat vs Dog Image Classifier - Training Script\n",
    "\n",
    "This script is responsible for training a **Support Vector Machine (SVM)** model to classify images of cats and dogs.\n",
    "\n",
    "### It performs the following steps:\n",
    "\n",
    "1. **Loads and preprocesses images** from the training folder.\n",
    "2. **Extracts HOG (Histogram of Oriented Gradients) features** from each image.\n",
    "3. **Reduces feature dimensionality** using PCA (Principal Component Analysis).\n",
    "4. **Scales the features** for standardization.\n",
    "5. **Trains an SVM classifier** with hyperparameter tuning using GridSearchCV.\n",
    "6. **Evaluates the trained model** on a validation set.\n",
    "7. **Saves the trained model** along with the scaler and PCA transformer for future use.\n",
    "\n",
    "**Output:** A trained model file named **`svm_model_hog_pca.pkl`** is saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1570b-17c0-40b6-8b30-3993c9cb0c8a",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9baab0-9d3d-40e3-944f-157bb962bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                           # For interacting with the file system\n",
    "import numpy as np                  # For array operations and numerical computations\n",
    "import pickle                       # To save and load the trained model\n",
    "from pathlib import Path            # For handling file paths in an OS-independent way\n",
    "\n",
    "from skimage.io import imread                   # To read image files\n",
    "from skimage.transform import resize            # To resize images to a fixed size\n",
    "from skimage.feature import hog                 # To extract HOG features\n",
    "from skimage.color import rgb2gray              # To convert images to grayscale\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # For splitting data and hyperparameter tuning\n",
    "from sklearn.preprocessing import StandardScaler                    # For feature normalization\n",
    "from sklearn.decomposition import PCA                               # To reduce dimensionality of features\n",
    "from sklearn import svm                                              # Support Vector Machine classifier\n",
    "from sklearn.metrics import accuracy_score, classification_report    # Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83cd4a-4a88-40c9-a155-90f4387f5dd5",
   "metadata": {},
   "source": [
    "## 2. Setting the Base Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61be4ab3-8f6a-4de8-8537-fe81406fa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = \"train/train\"  # Folder should contain labeled images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdcfaf-b7d7-489e-a64b-a9c4eb28031f",
   "metadata": {},
   "source": [
    "## 3. Defining Image Preprocessing & Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c4f067-a83e-4ded-8ea2-76174b672430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images and extract either raw pixel or HOG features\n",
    "# I wrote this function to load images, resize them to a fixed shape, convert them to grayscale\n",
    "# and then either flatten the raw pixels or extract HOG features depending on the `feature_type`.\n",
    "# HOG captures edge/texture info which helps distinguish between cats and dogs.\n",
    "\n",
    "def load_training_data(image_dir, img_size=(128, 128), feature_type='pixels'):\n",
    "    input_images = []   # To store image features\n",
    "    output_labels = []  # To store corresponding labels (0 for cat, 1 for dog)\n",
    "\n",
    "    for file in os.listdir(image_dir):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            file_path = os.path.join(image_dir, file)\n",
    "            img = imread(file_path)   # Read image from disk\n",
    "            \n",
    "            # Remove alpha channel if image has 4 channels\n",
    "            if img.shape[-1] == 4:\n",
    "                img = img[:, :, :3]\n",
    "\n",
    "            # Resize image and preserve its range\n",
    "            img_gray = resize(img, img_size, anti_aliasing=True, preserve_range=True)\n",
    "\n",
    "            # Convert RGB image to grayscale (required for HOG)\n",
    "            if img_gray.ndim == 3 and img_gray.shape[2] == 3:\n",
    "                img_gray = rgb2gray(img_gray)\n",
    "\n",
    "            # Feature extraction: either use raw pixels or HOG features\n",
    "            if feature_type == 'pixels':\n",
    "                input_images.append(img_gray.flatten())\n",
    "            elif feature_type == 'hog':\n",
    "                fd = hog(img_gray, orientations=9, pixels_per_cell=(8, 8),\n",
    "                         cells_per_block=(2, 2), visualize=False, channel_axis=None)\n",
    "                input_images.append(fd)\n",
    "\n",
    "            # Label assignment: 'cat' → 0, 'dog' → 1\n",
    "            label = 0 if 'cat' in file.lower() else 1\n",
    "            output_labels.append(label)\n",
    "\n",
    "    return np.array(input_images), np.array(output_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3721ae-8f1a-4a66-944c-0613b2004ed2",
   "metadata": {},
   "source": [
    "## 4. Training SVM with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10dd504-cdd0-4c7e-b823-32300981d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains an SVM model using GridSearch to find optimal hyperparameters\n",
    "# I split the data into train and test sets, scale it, perform grid search on C and gamma\n",
    "# and evaluate performance using accuracy and classification report\n",
    "\n",
    "def train_svm_model_with_gridsearch(X, y):\n",
    "    # Split into training and validation sets (75%-25% split)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "    # Standardize the features to have zero mean and unit variance\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 0.1, 0.01],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    # Initialize SVM with probability output enabled\n",
    "    svc = svm.SVC(probability=True)\n",
    "\n",
    "    # Use GridSearchCV to find the best combination of hyperparameters\n",
    "    clf = GridSearchCV(svc, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    print(\"Starting Grid Search...\")\n",
    "    clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "    print(f\"Best Parameters: {clf.best_params_}\")\n",
    "\n",
    "    # Evaluate performance on validation set\n",
    "    y_pred = clf.predict(x_test_scaled)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Cat', 'Dog']))\n",
    "\n",
    "    return clf.best_estimator_, scaler  # Return best model and the scaler used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a4e3c-fd56-4d5b-9743-936abd5a79a3",
   "metadata": {},
   "source": [
    "## 5. Loading Data and Applying HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18db745b-41c4-42ca-a64d-808f77c5d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and extracting HOG features...\n"
     ]
    }
   ],
   "source": [
    "# I use HOG because it captures edge and texture details that help differentiate cats from dogs\n",
    "print(\"Loading data and extracting HOG features...\")\n",
    "X_data, y_data = load_training_data(train_img_dir, img_size=(128, 128), feature_type='hog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bb424-adba-4efa-835f-da699b058ce4",
   "metadata": {},
   "source": [
    "## 6. Reducing Dataset Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e5da3e-c8d4-473f-8620-fe878317014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature dimension after HOG: 8100\n"
     ]
    }
   ],
   "source": [
    "# Reduce data to 8000 samples for faster training\n",
    "X_data, _, y_data, _ = train_test_split(\n",
    "    X_data, y_data,\n",
    "    train_size=8000,\n",
    "    stratify=y_data,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Original feature dimension after HOG: {X_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3bb368-538d-4348-823f-998f456b29d6",
   "metadata": {},
   "source": [
    "## 7. Applying PCA for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe2605f-d32a-48e6-b908-e6bd429da4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced feature dimension after PCA: 500\n",
      "Explained variance ratio by 500 components: 0.67\n"
     ]
    }
   ],
   "source": [
    "# I apply PCA to reduce noise and computation time; 500 components preserve most variance\n",
    "pca = PCA(n_components=500)\n",
    "X_data_reduced = pca.fit_transform(X_data)\n",
    "\n",
    "print(f\"Reduced feature dimension after PCA: {X_data_reduced.shape[1]}\")\n",
    "print(f\"Explained variance ratio by 500 components: {np.sum(pca.explained_variance_ratio_):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b26ac-ce6a-4bb2-a12c-119d768b1c77",
   "metadata": {},
   "source": [
    "## 8. Training the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224f98e2-2c6d-459c-8c6b-6bdadab22409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 71.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat       0.71      0.73      0.72      1000\n",
      "         Dog       0.72      0.70      0.71      1000\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.71      0.71      0.71      2000\n",
      "weighted avg       0.71      0.71      0.71      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the processed features\n",
    "model, scaler = train_svm_model_with_gridsearch(X_data_reduced, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b6976-1049-4750-97f8-327d2c65ffea",
   "metadata": {},
   "source": [
    "## 9. Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a841d52-4672-47b9-831f-7cd442a38037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: svm_model_hog_pca.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model, scaler, and PCA transformer to a pickle file for reuse\n",
    "model_path = \"svm_model_hog_pca.pkl\"\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump((model, scaler, pca), file)\n",
    "\n",
    "print(f\"Model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e92100-e06e-4d0b-8006-2668eb666017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
